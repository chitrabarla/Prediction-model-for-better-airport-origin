{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+\n",
      "|Year|Month|DayofMonth|DayOfWeek|DepTime|CRSDepTime|ArrTime|CRSArrTime|UniqueCarrier|FlightNum|TailNum|ActualElapsedTime|CRSElapsedTime|AirTime|ArrDelay|DepDelay|Origin|Dest|Distance|TaxiIn|TaxiOut|Cancelled|CancellationCode|Diverted|CarrierDelay|WeatherDelay|NASDelay|SecurityDelay|LateAircraftDelay|\n",
      "+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+\n",
      "|2001|    8|        27|        1|   1345|      1345|   1530|      1535|           WN|      574| N386@@|              105|           110|     93|      -5|       0|   OAK| SEA|     671|     7|      5|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|\n",
      "|2001|   12|         8|        6|   2033|      2039|   2149|      2159|           AS|      592| N775A�|               76|            80|     62|     -10|      -6|   SFO| PSP|     421|     5|      9|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|\n",
      "|2001|    1|        26|        5|   1506|      1340|   1630|      1500|           UA|     2684| N367�1|               84|            80|     60|      90|      86|   OAK| LAX|     337|     8|     16|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|\n",
      "|2001|    8|        16|        4|     NA|      1245|     NA|      1812|           DL|     1558| N308�1|               NA|           207|     NA|      NA|      NA|   OAK| DFW|    1456|     0|      0|        1|              NA|       0|          NA|          NA|      NA|           NA|               NA|\n",
      "|2001|    6|        13|        3|   1644|      1645|   1852|      1905|           UA|       61| N672�1|              308|           320|    291|     -13|      -1|   SFO| HNL|    2398|     2|     15|        0|              NA|       0|          NA|          NA|      NA|           NA|               NA|\n",
      "+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "var reader=spark.read.option(\"inferSchema\",true).option(\"header\",true).option(\"delimiter\",\",\")\n",
    "var data=reader.csv(\"./data.csv\")\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var data1=data.select(\"Year\",\"Month\",\"DayofMonth\",\"DayOfWeek\",\"CRSDepTime\",\"CRSArrTime\",\"UniqueCarrier\",\"FlightNum\",\"ArrDelay\",\"DepDelay\",\"Origin\",\"Cancelled\",\"Dest\").na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------+----------+----------+-------------+---------+--------+--------+------+----+\n",
      "|Year|Month|DayofMonth|DayOfWeek|CRSDepTime|CRSArrTime|UniqueCarrier|FlightNum|ArrDelay|DepDelay|Origin|Dest|\n",
      "+----+-----+----------+---------+----------+----------+-------------+---------+--------+--------+------+----+\n",
      "|2001|    8|        27|        1|      1345|      1535|           WN|      574|      -5|       0|   OAK| SEA|\n",
      "|2001|   12|         8|        6|      2039|      2159|           AS|      592|     -10|      -6|   SFO| PSP|\n",
      "|2001|    1|        26|        5|      1340|      1500|           UA|     2684|      90|      86|   OAK| LAX|\n",
      "|2001|    6|        13|        3|      1645|      1905|           UA|       61|     -13|      -1|   SFO| HNL|\n",
      "|2001|   10|        14|        7|      1547|      1726|           AS|      339|      42|      47|   SFO| PDX|\n",
      "+----+-----+----------+---------+----------+----------+-------------+---------+--------+--------+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var data2=data1.where(expr(\"Cancelled==0\")).drop(\"Cancelled\")\n",
    "data2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------+----------+----------+---------+--------+--------+------+----+-------+\n",
      "|Year|Month|DayofMonth|DayOfWeek|CRSDepTime|CRSArrTime|FlightNum|ArrDelay|DepDelay|Origin|Dest|Carrier|\n",
      "+----+-----+----------+---------+----------+----------+---------+--------+--------+------+----+-------+\n",
      "|2001|    8|        27|        1|      1345|      1535|      574|      -5|       0|   OAK| SEA|    0.0|\n",
      "|2001|   12|         8|        6|      2039|      2159|      592|     -10|      -6|   SFO| PSP|    3.0|\n",
      "|2001|    1|        26|        5|      1340|      1500|     2684|      90|      86|   OAK| LAX|    1.0|\n",
      "|2001|    6|        13|        3|      1645|      1905|       61|     -13|      -1|   SFO| HNL|    1.0|\n",
      "|2001|   10|        14|        7|      1547|      1726|      339|      42|      47|   SFO| PDX|    3.0|\n",
      "+----+-----+----------+---------+----------+----------+---------+--------+--------+------+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.{StringIndexer}\n",
    "var data3=new StringIndexer().setInputCol(\"UniqueCarrier\").setOutputCol(\"Carrier\").fit(data2).transform(data2).drop(\"UniqueCarrier\")\n",
    "data3.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------+----------+----------+---------+--------+--------+------+----+-------+----------+\n",
      "|Year|Month|DayofMonth|DayOfWeek|CRSDepTime|CRSArrTime|FlightNum|ArrDelay|DepDelay|Origin|Dest|Carrier|OriginCode|\n",
      "+----+-----+----------+---------+----------+----------+---------+--------+--------+------+----+-------+----------+\n",
      "|2001|    8|        27|        1|      1345|      1535|      574|      -5|       0|   OAK| SEA|    0.0|       0.0|\n",
      "|2001|   12|         8|        6|      2039|      2159|      592|     -10|      -6|   SFO| PSP|    3.0|       1.0|\n",
      "|2001|    1|        26|        5|      1340|      1500|     2684|      90|      86|   OAK| LAX|    1.0|       0.0|\n",
      "|2001|    6|        13|        3|      1645|      1905|       61|     -13|      -1|   SFO| HNL|    1.0|       1.0|\n",
      "|2001|   10|        14|        7|      1547|      1726|      339|      42|      47|   SFO| PDX|    3.0|       1.0|\n",
      "+----+-----+----------+---------+----------+----------+---------+--------+--------+------+----+-------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val data4=new StringIndexer().setInputCol(\"Origin\").setOutputCol(\"OriginCode\").fit(data3).transform(data3)\n",
    "data4.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------+----------+----------+---------+--------+--------+------+----+-------+----------+--------------+\n",
      "|Year|Month|DayofMonth|DayOfWeek|CRSDepTime|CRSArrTime|FlightNum|ArrDelay|DepDelay|Origin|Dest|Carrier|OriginCode|FlightNumIndex|\n",
      "+----+-----+----------+---------+----------+----------+---------+--------+--------+------+----+-------+----------+--------------+\n",
      "|2001|    8|        27|        1|      1345|      1535|      574|      -5|       0|   OAK| SEA|    0.0|       0.0|          96.0|\n",
      "|2001|   12|         8|        6|      2039|      2159|      592|     -10|      -6|   SFO| PSP|    3.0|       1.0|          73.0|\n",
      "|2001|    1|        26|        5|      1340|      1500|     2684|      90|      86|   OAK| LAX|    1.0|       0.0|         565.0|\n",
      "|2001|    6|        13|        3|      1645|      1905|       61|     -13|      -1|   SFO| HNL|    1.0|       1.0|         706.0|\n",
      "|2001|   10|        14|        7|      1547|      1726|      339|      42|      47|   SFO| PDX|    3.0|       1.0|          74.0|\n",
      "+----+-----+----------+---------+----------+----------+---------+--------+--------+------+----+-------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val data5=new StringIndexer().setInputCol(\"FlightNum\").setOutputCol(\"FlightNumIndex\").fit(data4).transform(data4)\n",
    "data5.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------+----------+----------+--------+--------+------+-------+----------+--------------+-----------+\n",
      "|Year|Month|DayofMonth|DayOfWeek|CRSDepTime|CRSArrTime|ArrDelay|DepDelay|Origin|Carrier|OriginCode|FlightNumIndex|Destination|\n",
      "+----+-----+----------+---------+----------+----------+--------+--------+------+-------+----------+--------------+-----------+\n",
      "|2001|    8|        27|        1|      1345|      1535|      -5|       0|   OAK|    0.0|       0.0|          96.0|        1.0|\n",
      "|2001|   12|         8|        6|      2039|      2159|     -10|      -6|   SFO|    3.0|       1.0|          73.0|       38.0|\n",
      "|2001|    1|        26|        5|      1340|      1500|      90|      86|   OAK|    1.0|       0.0|         565.0|        0.0|\n",
      "|2001|    6|        13|        3|      1645|      1905|     -13|      -1|   SFO|    1.0|       1.0|         706.0|       22.0|\n",
      "|2001|   10|        14|        7|      1547|      1726|      42|      47|   SFO|    3.0|       1.0|          74.0|        7.0|\n",
      "+----+-----+----------+---------+----------+----------+--------+--------+------+-------+----------+--------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val data6=new StringIndexer().setInputCol(\"Dest\").setOutputCol(\"Destination\").fit(data5).transform(data5).drop(\"Dest\").drop(\"FlightNum\")\n",
    "data6.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------+----------+----------+--------+--------+------+-------+----------+--------------+-----------+-----+\n",
      "|Year|Month|DayofMonth|DayOfWeek|CRSDepTime|CRSArrTime|ArrDelay|DepDelay|Origin|Carrier|OriginCode|FlightNumIndex|Destination|delay|\n",
      "+----+-----+----------+---------+----------+----------+--------+--------+------+-------+----------+--------------+-----------+-----+\n",
      "|2001|    8|        27|        1|      1345|      1535|      -5|       0|   OAK|    0.0|       0.0|          96.0|        1.0|    0|\n",
      "|2001|   12|         8|        6|      2039|      2159|     -10|      -6|   SFO|    3.0|       1.0|          73.0|       38.0|    0|\n",
      "|2001|    1|        26|        5|      1340|      1500|      90|      86|   OAK|    1.0|       0.0|         565.0|        0.0|    0|\n",
      "|2001|    6|        13|        3|      1645|      1905|     -13|      -1|   SFO|    1.0|       1.0|         706.0|       22.0|    0|\n",
      "|2001|   10|        14|        7|      1547|      1726|      42|      47|   SFO|    3.0|       1.0|          74.0|        7.0|    0|\n",
      "+----+-----+----------+---------+----------+----------+--------+--------+------+-------+----------+--------------+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var data7=data6.withColumn(\"delay\",when(col(\"ArrDelay\")>=100, 1).otherwise(0))\n",
    "data7.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.feature.RFormula\n",
    "val rFormula= new RFormula().setFormula(\"delay ~ Year+Month+DayofMonth+DayOfWeek+CRSDepTime+CRSArrTime+DepDelay+Carrier+FlightNumIndex+OriginCode+Destination\")\n",
    "var preparedData=rFormula.fit(data7).transform(data7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val Array(trainData, testData)= preparedData.randomSplit(Array(0.8,0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.classification.LogisticRegression\n",
    "val logisticRegression= new LogisticRegression()\n",
    "val logisticRegressionModel = logisticRegression.fit(trainData)\n",
    "val predictionsLogistic = logisticRegressionModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Precision = 0.5\n",
      " Recall = 0.23076923\n",
      " Accuracy= 0.9723404\n"
     ]
    }
   ],
   "source": [
    "val labelPositives = predictionsLogistic.where(expr(\"label == 1.0\"))\n",
    "val labelNegatives = predictionsLogistic.where(expr(\"label == 0.0\"))\n",
    "val falseNegatives = labelPositives.where(expr(\"label != prediction\")).count()\n",
    "val falsePositives = labelNegatives.where(expr(\"label != prediction\")).count()\n",
    "val trueNegatives  = labelNegatives.where(expr(\"label == prediction\")).count()\n",
    "val truePositives  = labelPositives.where(expr(\"label == prediction\")).count()\n",
    "println(\" Precision = \" + truePositives.toFloat/(falsePositives + truePositives))\n",
    "println(\" Recall = \" + truePositives.toFloat/(falseNegatives + truePositives))\n",
    "println(\" Accuracy= \" + (truePositives+trueNegatives).toFloat/(falsePositives + trueNegatives+falseNegatives + truePositives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label|Errors|\n",
      "+-----+------+\n",
      "|  0.0|     3|\n",
      "|  1.0|    10|\n",
      "+-----+------+\n",
      "\n",
      "+-----+-------+                                                                 \n",
      "|label|Correct|\n",
      "+-----+-------+\n",
      "|  0.0|    454|\n",
      "|  1.0|      3|\n",
      "+-----+-------+\n",
      "\n",
      "True Positive Rate or Sensitivity or Recall for Logistic Regression :0.5\n",
      "\n",
      "False Positive Rate for Logistic Regression :0.5\n",
      "\n",
      "misclassification rate of Logistic Regression  :0.027659574468085105\n",
      "\n",
      "Accuracy  of Logistic Regression :0.9723404255319149\n",
      "\n",
      "Specificity  of  Logistic Regression :0.9934354485776805\n",
      "\n",
      "Precision  of  Logistic Regression :0.5\n",
      "\n",
      "Prevalence  of Logistic Regression :0.027659574468085105\n",
      "\n",
      "+-----+------+-------+-----+----------------------------+--------------------------+\n",
      "|label|Errors|Correct|Total|FalsePositive  FalseNegative|TrueNegative  TruePositive|\n",
      "+-----+------+-------+-----+----------------------------+--------------------------+\n",
      "|  0.0|     3|    454|  457|        0.006564551422319475|         99.34354485776805|\n",
      "|  1.0|    10|      3|   13|          0.7692307692307693|        23.076923076923077|\n",
      "+-----+------+-------+-----+----------------------------+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val wrongPredictions_logistic = predictionsLogistic.where(expr(\"label != prediction\"))\n",
    "val countErrors_logistic = wrongPredictions_logistic.groupBy(\"label\").agg(count(\"prediction\").alias(\"Errors\"))\n",
    "countErrors_logistic.show\n",
    "var TP_logistic = 0.0\n",
    "var TN_logistic = 0.0\n",
    "var FP_logistic = 0.0\n",
    "var FN_logistic = 0.0\n",
    "\n",
    "val correctPredictions_logistic = predictionsLogistic.where(expr(\"label == prediction\"))\n",
    "val countCorrectPredictions_logistic = correctPredictions_logistic.groupBy(\"label\").agg(count(\"prediction\").alias(\"Correct\"))\n",
    "countCorrectPredictions_logistic.show\n",
    "\n",
    "\n",
    "if (countCorrectPredictions_logistic.select(\"Correct\").where(expr(\"label == 0.0\")).count() >0) {\n",
    "  TN_logistic = countCorrectPredictions_logistic.select(\"Correct\").where(expr(\"label == 0.0\")).first().getLong(0)\n",
    "}\n",
    "\n",
    "if (countCorrectPredictions_logistic.select(\"Correct\").where(expr(\"label == 1.0\")).count() >0) {\n",
    "  TP_logistic = countCorrectPredictions_logistic.select(\"Correct\").where(expr(\"label == 1.0\")).first().getLong(0)\n",
    "}\n",
    "\n",
    "if (countErrors_logistic.select(\"Errors\").where(expr(\"label == 0.0\")).count() >0) {\n",
    "  FP_logistic = countErrors_logistic.select(\"Errors\").where(expr(\"Label == 0.0\")).first().getLong(0)\n",
    "}\n",
    "\n",
    "if (countErrors_logistic.select(\"Errors\").where(expr(\"label == 1.0\")).count() >0)\n",
    "{\n",
    "  FN_logistic = countErrors_logistic.select(\"Errors\").where(expr(\"label == 1.0\")).first().getLong(0)\n",
    "}\n",
    "\n",
    "\n",
    "var TruePositiveRate_logistic_regression = TP_logistic/(TP_logistic+FP_logistic)\n",
    "println( \"True Positive Rate or Sensitivity or Recall for Logistic Regression :\" +TruePositiveRate_logistic_regression+\"\\n\")\n",
    "var FalsePositiveRate_logistic_regression = FP_logistic/(TP_logistic+ FP_logistic)\n",
    "println( \"False Positive Rate for Logistic Regression :\" +FalsePositiveRate_logistic_regression+\"\\n\")\n",
    "\n",
    "\n",
    "var total_logistic_regression = TP_logistic+TN_logistic+FP_logistic+FN_logistic\n",
    "var misclassificationRate_logistic_regression = (FP_logistic+FN_logistic)/total_logistic_regression\n",
    "println(\"misclassification rate of Logistic Regression  :\"+misclassificationRate_logistic_regression+\"\\n\")\n",
    "\n",
    "val accuracy_logistic_regression =(TP_logistic+TN_logistic)/total_logistic_regression\n",
    "println(\"Accuracy  of Logistic Regression :\" + accuracy_logistic_regression+\"\\n\")\n",
    "\n",
    "var  actual_logistic_regression = TN_logistic+FP_logistic\n",
    "var  specificity_logistic_regression = TN_logistic/actual_logistic_regression\n",
    "println(\"Specificity  of  Logistic Regression :\"+specificity_logistic_regression+\"\\n\")\n",
    "\n",
    "var  precision_logistic_regression = TP_logistic/(FP_logistic+TP_logistic)\n",
    "println(\"Precision  of  Logistic Regression :\"+precision_logistic_regression+\"\\n\")\n",
    "\n",
    "var  prevalence_logistic_regression = (FN_logistic+TP_logistic)/total_logistic_regression\n",
    "println(\"Prevalence  of Logistic Regression :\"+prevalence_logistic_regression+\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "val TableOne_logistic_regression = countErrors_logistic.join(countCorrectPredictions_logistic, Seq(\"Label\"), \"outer\").na.fill(0,Seq(\"Errors\")).na.fill(0,Seq(\"Correct\"))\n",
    "val TableTwo_logistic_regression = TableOne_logistic_regression.withColumn(\"Total\",col(\"Errors\")+col(\"Correct\"))\n",
    "val TableThree_logistic_regression = TableTwo_logistic_regression.withColumn(\"FalsePositive  FalseNegative\",\n",
    "  (col(\"Errors\")/col(\"Total\"))).withColumn(\"TrueNegative  TruePositive\", ((col(\"Correct\")/col(\"Total\"))*100))\n",
    "val TableThreeSC = TableThree_logistic_regression.coalesce(1)\n",
    "TableThreeSC.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.classification.NaiveBayes\n",
    "val naiveBayesModel = new NaiveBayes().fit(trainData)\n",
    "val predictionsNaiveBayes = naiveBayesModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+----------+\n",
      "|label|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+----------+\n",
      "|  0.0|[-5836.1150802666...|[1.0,7.7013586034...|       0.0|\n",
      "|  0.0|[-5519.8737041739...|[1.0,4.0632703799...|       0.0|\n",
      "|  0.0|[-7857.3239270825...|[1.0,1.0978096787...|       0.0|\n",
      "|  0.0|[-6143.7732729811...|[0.99999999999998...|       0.0|\n",
      "|  0.0|[-8353.2904727046...|[8.16362058306430...|       1.0|\n",
      "+-----+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictionsNaiveBayes.select(\"label\",\"rawPrediction\",\"probability\",\"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Precision = 0.042168673\n",
      " Recall = 0.53846157\n",
      " Accuracy= 0.64893615\n"
     ]
    }
   ],
   "source": [
    "val labelPositives = predictionsNaiveBayes.where(expr(\"label == 1.0\"))\n",
    "val labelNegatives = predictionsNaiveBayes.where(expr(\"label == 0.0\"))\n",
    "val falseNegatives = labelPositives.where(expr(\"label != prediction\")).count()\n",
    "val falsePositives = labelNegatives.where(expr(\"label != prediction\")).count()\n",
    "val trueNegatives  = labelNegatives.where(expr(\"label == prediction\")).count()\n",
    "val truePositives  = labelPositives.where(expr(\"label == prediction\")).count()\n",
    "println(\" Precision = \" + truePositives.toFloat/(falsePositives + truePositives))\n",
    "println(\" Recall = \" + truePositives.toFloat/(falseNegatives + truePositives))\n",
    "println(\" Accuracy= \" + (truePositives+trueNegatives).toFloat/(falsePositives + trueNegatives+falseNegatives + truePositives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label|Errors|\n",
      "+-----+------+\n",
      "|  0.0|   159|\n",
      "|  1.0|     6|\n",
      "+-----+------+\n",
      "\n",
      "+-----+-------+\n",
      "|label|Correct|\n",
      "+-----+-------+\n",
      "|  0.0|    298|\n",
      "|  1.0|      7|\n",
      "+-----+-------+\n",
      "\n",
      "True Positive Rate or Sensitivity or Recall for Bayes Regression :0.04216867469879518\n",
      "\n",
      "False Positive Rate for Bayes Regression :0.9578313253012049\n",
      "\n",
      "misclassification rate of Bayes Regression  :0.35106382978723405\n",
      "\n",
      "Accuracy  of Bayes Regression :0.648936170212766\n",
      "\n",
      "Specificity  of  Bayes Regression :0.6520787746170679\n",
      "\n",
      "Precision  of  Bayes Regression :0.04216867469879518\n",
      "\n",
      "Prevalence  of Bayes Regression :0.027659574468085105\n",
      "\n",
      "+-----+------+-------+-----+----------------------------+--------------------------+\n",
      "|label|Errors|Correct|Total|FalsePositive  FalseNegative|TrueNegative  TruePositive|\n",
      "+-----+------+-------+-----+----------------------------+--------------------------+\n",
      "|  0.0|   159|    298|  457|          0.3479212253829322|         65.20787746170679|\n",
      "|  1.0|     6|      7|   13|         0.46153846153846156|         53.84615384615385|\n",
      "+-----+------+-------+-----+----------------------------+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val wrongPredictions_bayes = predictionsNaiveBayes.where(expr(\"label != prediction\"))\n",
    "val countErrors_bayes = wrongPredictions_bayes.groupBy(\"label\").agg(count(\"prediction\").alias(\"Errors\"))\n",
    "countErrors_bayes.show\n",
    "var TP_bayes = 0.0\n",
    "var TN_bayes = 0.0\n",
    "var FP_bayes = 0.0\n",
    "var FN_bayes = 0.0\n",
    "\n",
    "val correctPredictions_bayes = predictionsNaiveBayes.where(expr(\"label == prediction\"))\n",
    "val countCorrectPredictions_bayes = correctPredictions_bayes.groupBy(\"label\").agg(count(\"prediction\").alias(\"Correct\"))\n",
    "countCorrectPredictions_bayes.show\n",
    "\n",
    "\n",
    "if (countCorrectPredictions_bayes.select(\"Correct\").where(expr(\"label == 0.0\")).count() >0) {\n",
    "  TN_bayes = countCorrectPredictions_bayes.select(\"Correct\").where(expr(\"label == 0.0\")).first().getLong(0)\n",
    "}\n",
    "\n",
    "if (countCorrectPredictions_bayes.select(\"Correct\").where(expr(\"label == 1.0\")).count() >0) {\n",
    "  TP_bayes = countCorrectPredictions_bayes.select(\"Correct\").where(expr(\"label == 1.0\")).first().getLong(0)\n",
    "}\n",
    "\n",
    "if (countErrors_bayes.select(\"Errors\").where(expr(\"label == 0.0\")).count() >0) {\n",
    "  FP_bayes = countErrors_bayes.select(\"Errors\").where(expr(\"Label == 0.0\")).first().getLong(0)\n",
    "}\n",
    "\n",
    "if (countErrors_bayes.select(\"Errors\").where(expr(\"label == 1.0\")).count() >0)\n",
    "{\n",
    "  FN_bayes = countErrors_bayes.select(\"Errors\").where(expr(\"label == 1.0\")).first().getLong(0)\n",
    "}\n",
    "\n",
    "\n",
    "var TruePositiveRate_bayes_regression = TP_bayes/(TP_bayes+FP_bayes)\n",
    "println( \"True Positive Rate or Sensitivity or Recall for Bayes Regression :\" +TruePositiveRate_bayes_regression+\"\\n\")\n",
    "var FalsePositiveRate_bayes_regression = FP_bayes/(TP_bayes+ FP_bayes)\n",
    "println( \"False Positive Rate for Bayes Regression :\" +FalsePositiveRate_bayes_regression+\"\\n\")\n",
    "\n",
    "\n",
    "var total_bayes_regression = TP_bayes+TN_bayes+FP_bayes+FN_bayes\n",
    "var misclassificationRate_bayes_regression = (FP_bayes+FN_bayes)/total_bayes_regression\n",
    "println(\"misclassification rate of Bayes Regression  :\"+misclassificationRate_bayes_regression+\"\\n\")\n",
    "\n",
    "val accuracy_bayes_regression =(TP_bayes+TN_bayes)/total_bayes_regression\n",
    "println(\"Accuracy  of Bayes Regression :\" + accuracy_bayes_regression+\"\\n\")\n",
    "\n",
    "var  actual_bayes_regression = TN_bayes+FP_bayes\n",
    "var  specificity_bayes_regression = TN_bayes/actual_bayes_regression\n",
    "println(\"Specificity  of  Bayes Regression :\"+specificity_bayes_regression+\"\\n\")\n",
    "\n",
    "var  precision_bayes_regression = TP_bayes/(FP_bayes+TP_bayes)\n",
    "println(\"Precision  of  Bayes Regression :\"+precision_bayes_regression+\"\\n\")\n",
    "\n",
    "var  prevalence_bayes_regression = (FN_bayes+TP_bayes)/total_bayes_regression\n",
    "println(\"Prevalence  of Bayes Regression :\"+prevalence_bayes_regression+\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "val TableOne_bayes_regression = countErrors_bayes.join(countCorrectPredictions_bayes, Seq(\"Label\"), \"outer\").na.fill(0,Seq(\"Errors\")).na.fill(0,Seq(\"Correct\"))\n",
    "val TableTwo_bayes_regression = TableOne_bayes_regression.withColumn(\"Total\",col(\"Errors\")+col(\"Correct\"))\n",
    "val TableThree_bayes_regression = TableTwo_bayes_regression.withColumn(\"FalsePositive  FalseNegative\",\n",
    "  (col(\"Errors\")/col(\"Total\"))).withColumn(\"TrueNegative  TruePositive\", ((col(\"Correct\")/col(\"Total\"))*100))\n",
    "val TableThreeSC = TableThree_bayes_regression.coalesce(1)\n",
    "TableThreeSC.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.classification.LinearSVC\n",
    "val lsvm = new LinearSVC().setMaxIter(10).setRegParam(0.1)\n",
    "val lsvmModel = lsvm.fit(trainData)\n",
    "val predictionsSvm = lsvmModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Precision = 1.0\n",
      " Recall = 0.16666667\n",
      " Accuracy= 0.98868775\n"
     ]
    }
   ],
   "source": [
    "val labelPositives = predictionsSvm.where(expr(\"label == 1.0\"))\n",
    "val labelNegatives = predictionsSvm.where(expr(\"label == 0.0\"))\n",
    "val falseNegatives = labelPositives.where(expr(\"label != prediction\")).count()\n",
    "val falsePositives = labelNegatives.where(expr(\"label != prediction\")).count()\n",
    "val trueNegatives  = labelNegatives.where(expr(\"label == prediction\")).count()\n",
    "val truePositives  = labelPositives.where(expr(\"label == prediction\")).count()\n",
    "println(\" Precision = \" + truePositives.toFloat/(falsePositives + truePositives))\n",
    "println(\" Recall = \" + truePositives.toFloat/(falseNegatives + truePositives))\n",
    "println(\" Accuracy= \" + (truePositives+trueNegatives).toFloat/(falsePositives + trueNegatives+falseNegatives + truePositives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label|Errors|\n",
      "+-----+------+\n",
      "|  1.0|     5|\n",
      "+-----+------+\n",
      "\n",
      "+-----+-------+\n",
      "|label|Correct|\n",
      "+-----+-------+\n",
      "|  0.0|    436|\n",
      "|  1.0|      1|\n",
      "+-----+-------+\n",
      "\n",
      "True Positive Rate or Sensitivity or Recall for Svm Regression :1.0\n",
      "\n",
      "False Positive Rate for Svm Regression :0.0\n",
      "\n",
      "misclassification rate of Svm Regression  :0.011312217194570135\n",
      "\n",
      "Accuracy  of Svm Regression :0.9886877828054299\n",
      "\n",
      "Specificity  of  Svm Regression :1.0\n",
      "\n",
      "Precision  of  Svm Regression :1.0\n",
      "\n",
      "Prevalence  of Svm Regression :0.013574660633484163\n",
      "\n",
      "+-----+------+-------+-----+----------------------------+--------------------------+\n",
      "|label|Errors|Correct|Total|FalsePositive  FalseNegative|TrueNegative  TruePositive|\n",
      "+-----+------+-------+-----+----------------------------+--------------------------+\n",
      "|  0.0|     0|    436|  436|                         0.0|                     100.0|\n",
      "|  1.0|     5|      1|    6|          0.8333333333333334|        16.666666666666664|\n",
      "+-----+------+-------+-----+----------------------------+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val wrongPredictions_svm = predictionsSvm.where(expr(\"label != prediction\"))\n",
    "val countErrors_svm = wrongPredictions_svm.groupBy(\"label\").agg(count(\"prediction\").alias(\"Errors\"))\n",
    "countErrors_svm.show\n",
    "var TP_svm = 0.0\n",
    "var TN_svm = 0.0\n",
    "var FP_svm = 0.0\n",
    "var FN_svm = 0.0\n",
    "\n",
    "val correctPredictions_svm = predictionsSvm.where(expr(\"label == prediction\"))\n",
    "val countCorrectPredictions_svm = correctPredictions_svm.groupBy(\"label\").agg(count(\"prediction\").alias(\"Correct\"))\n",
    "countCorrectPredictions_svm.show\n",
    "\n",
    "\n",
    "if (countCorrectPredictions_svm.select(\"Correct\").where(expr(\"label == 0.0\")).count() >0) {\n",
    "  TN_svm = countCorrectPredictions_svm.select(\"Correct\").where(expr(\"label == 0.0\")).first().getLong(0)\n",
    "}\n",
    "\n",
    "if (countCorrectPredictions_svm.select(\"Correct\").where(expr(\"label == 1.0\")).count() >0) {\n",
    "  TP_svm = countCorrectPredictions_svm.select(\"Correct\").where(expr(\"label == 1.0\")).first().getLong(0)\n",
    "}\n",
    "\n",
    "if (countErrors_svm.select(\"Errors\").where(expr(\"label == 0.0\")).count() >0) {\n",
    "  FP_svm = countErrors_svm.select(\"Errors\").where(expr(\"Label == 0.0\")).first().getLong(0)\n",
    "}\n",
    "\n",
    "if (countErrors_svm.select(\"Errors\").where(expr(\"label == 1.0\")).count() >0)\n",
    "{\n",
    "  FN_svm = countErrors_svm.select(\"Errors\").where(expr(\"label == 1.0\")).first().getLong(0)\n",
    "}\n",
    "\n",
    "\n",
    "var TruePositiveRate_svm_regression = TP_svm/(TP_svm+FP_svm)\n",
    "println( \"True Positive Rate or Sensitivity or Recall for Svm Regression :\" +TruePositiveRate_svm_regression+\"\\n\")\n",
    "var FalsePositiveRate_svm_regression = FP_svm/(TP_svm+ FP_svm)\n",
    "println( \"False Positive Rate for Svm Regression :\" +FalsePositiveRate_svm_regression+\"\\n\")\n",
    "\n",
    "\n",
    "var total_svm_regression = TP_svm+TN_svm+FP_svm+FN_svm\n",
    "var misclassificationRate_svm_regression = (FP_svm+FN_svm)/total_svm_regression\n",
    "println(\"misclassification rate of Svm Regression  :\"+misclassificationRate_svm_regression+\"\\n\")\n",
    "\n",
    "val accuracy_svm_regression =(TP_svm+TN_svm)/total_svm_regression\n",
    "println(\"Accuracy  of Svm Regression :\" + accuracy_svm_regression+\"\\n\")\n",
    "\n",
    "var  actual_svm_regression = TN_svm+FP_svm\n",
    "var  specificity_svm_regression = TN_svm/actual_svm_regression\n",
    "println(\"Specificity  of  Svm Regression :\"+specificity_svm_regression+\"\\n\")\n",
    "\n",
    "var  precision_svm_regression = TP_svm/(FP_svm+TP_svm)\n",
    "println(\"Precision  of  Svm Regression :\"+precision_svm_regression+\"\\n\")\n",
    "\n",
    "var  prevalence_svm_regression = (FN_svm+TP_svm)/total_svm_regression\n",
    "println(\"Prevalence  of Svm Regression :\"+prevalence_svm_regression+\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "val TableOne_svm_regression = countErrors_svm.join(countCorrectPredictions_svm, Seq(\"Label\"), \"outer\").na.fill(0,Seq(\"Errors\")).na.fill(0,Seq(\"Correct\"))\n",
    "val TableTwo_svm_regression = TableOne_svm_regression.withColumn(\"Total\",col(\"Errors\")+col(\"Correct\"))\n",
    "val TableThree_svm_regression = TableTwo_svm_regression.withColumn(\"FalsePositive  FalseNegative\",\n",
    "  (col(\"Errors\")/col(\"Total\"))).withColumn(\"TrueNegative  TruePositive\", ((col(\"Correct\")/col(\"Total\"))*100))\n",
    "val TableThreeSC = TableThree_svm_regression.coalesce(1)\n",
    "TableThreeSC.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "file_extension": ".scala",
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
